@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{orekondy2019knockoff,
  title={Knockoff nets: Stealing functionality of black-box models},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition(CVPR)},
  pages={4954--4963},
  year={2019}
}

@article{orekondy2019prediction,
  title={Prediction poisoning: Towards defenses against dnn model stealing attacks},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  journal={International Conference on Learning Representations (ICLR)},
  year={2019}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{DD_STB,
  title     = "画像識別における形状・テクスチャ偏重度と二重降下現象の関係について",
  author    = "秀弥, \UTF{9AD9}橋 and 中順, 井上 and 理央, 横田 and 裕雄, 片岡 and 英作, 前田",
  abstract  = "ある条件下における機械学習の学習性能は，学習エポック数やモデル容量に対して二重降下と呼ばれる奇妙な現象が起こる．また，画像認識タスクに対する深層学習では，形状特徴に関する学習とテクスチャ特徴に対する学習が異なる時間経過をとることも知られている．これら二つの現象間の関係性に着目し，タスク，実験条件などを変化させた実験を行い，学習結果の分析を行った．ImageNetによる事前学習の有無，ラベルノイズ負荷の有無などによって異なる学習経過をとる一方で，二つの現象に特徴的な変化のタイミングは一致する傾向が見られた．",
  journal   = "IEICE Conferences Archives",
  publisher = "The Institute of Electronics, Information and Communication
               Engineers",
  volume    = "IEICE-122",
  number    = "IEICE-PRMU-404,IEICE-IBISML-405",
  pages     = "IEICE--PRMU--13,IEICE--IBISML--13--IEICE--PRMU--16,IEICE--IBISML--16",
  month     =  feb,
  year      =  2023
}


@ARTICLE{Belkin2018-yx,
  title         = "Reconciling modern machine learning practice and the
                   bias-variance trade-off",
  author        = "Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal,
                   Soumik",
  abstract      = "Breakthroughs in machine learning are rapidly changing
                   science and society, yet our fundamental understanding of
                   this technology has lagged far behind. Indeed, one of the
                   central tenets of the field, the bias-variance trade-off,
                   appears to be at odds with the observed behavior of methods
                   used in the modern machine learning practice. The
                   bias-variance trade-off implies that a model should balance
                   under-fitting and over-fitting: rich enough to express
                   underlying structure in data, simple enough to avoid fitting
                   spurious patterns. However, in the modern practice, very
                   rich models such as neural networks are trained to exactly
                   fit (i.e., interpolate) the data. Classically, such models
                   would be considered over-fit, and yet they often obtain high
                   accuracy on test data. This apparent contradiction has
                   raised questions about the mathematical foundations of
                   machine learning and their relevance to practitioners. In
                   this paper, we reconcile the classical understanding and the
                   modern practice within a unified performance curve. This
                   ``double descent'' curve subsumes the textbook U-shaped
                   bias-variance trade-off curve by showing how increasing
                   model capacity beyond the point of interpolation results in
                   improved performance. We provide evidence for the existence
                   and ubiquity of double descent for a wide spectrum of models
                   and datasets, and we posit a mechanism for its emergence.
                   This connection between the performance and the structure of
                   machine learning models delineates the limits of classical
                   analyses, and has implications for both the theory and
                   practice of machine learning.",
  month         =  dec,
  year          =  2018,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML",
  eprint        = "1812.11118"
}

@ARTICLE{Nakkiran2021-vf,
  title     = "Deep double descent: where bigger models and more data hurt*",
  author    = "Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang,
               Tristan and Barak, Boaz and Sutskever, Ilya",
  abstract  = "Deep double descent: where bigger models and more data hurt* ,
               Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz
               Barak, Ilya Sutskever",
  journal   = "J. Stat. Mech.",
  publisher = "IOP Publishing",
  volume    =  2021,
  number    =  12,
  pages     = "124003",
  month     =  dec,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Esser2020-bk,
  title         = "A Disentangling Invertible Interpretation Network for
                   Explaining Latent Representations",
  author        = "Esser, Patrick and Rombach, Robin and Ommer, Bj{\"o}rn",
  abstract      = "Neural networks have greatly boosted performance in computer
                   vision by learning powerful representations of input data.
                   The drawback of end-to-end training for maximal overall
                   performance are black-box models whose hidden
                   representations are lacking interpretability: Since
                   distributed coding is optimal for latent layers to improve
                   their robustness, attributing meaning to parts of a hidden
                   feature vector or to individual neurons is hindered. We
                   formulate interpretation as a translation of hidden
                   representations onto semantic concepts that are
                   comprehensible to the user. The mapping between both domains
                   has to be bijective so that semantic modifications in the
                   target domain correctly alter the original representation.
                   The proposed invertible interpretation network can be
                   transparently applied on top of existing architectures with
                   no need to modify or retrain them. Consequently, we
                   translate an original representation to an equivalent yet
                   interpretable one and backwards without affecting the
                   expressiveness and performance of the original. The
                   invertible interpretation network disentangles the hidden
                   representation into separate, semantically meaningful
                   concepts. Moreover, we present an efficient approach to
                   define semantic concepts by only sketching two images and
                   also an unsupervised strategy. Experimental evaluation
                   demonstrates the wide applicability to interpretation of
                   existing classification and image generation networks as
                   well as to semantically guided image manipulation.",
  month         =  apr,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "2004.13166"
}

@INPROCEEDINGS{He2016-et,
  title     = "Deep Residual Learning for Image Recognition",
  booktitle = "2016 {IEEE} Conference on Computer Vision and Pattern
               Recognition ({CVPR})",
  author    = "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
  abstract  = "Deeper neural networks are more difficult to train. We present a
               residual learning framework to ease the training of networks
               that are substantially deeper than those used previously. We
               explicitly reformulate the layers as learning residual functions
               with reference to the layer inputs, instead of learning
               unreferenced functions. We provide comprehensive empirical
               evidence showing that these residual networks are easier to
               optimize, and can gain accuracy from considerably increased
               depth. On the ImageNet dataset we evaluate residual nets with a
               depth of up to 152 layers - 8$\times$ deeper than VGG nets [40]
               but still having lower complexity. An ensemble of these residual
               nets achieves 3.57\% error on the ImageNet test set. This result
               won the 1st place on the ILSVRC 2015 classification task. We
               also present analysis on CIFAR-10 with 100 and 1000 layers. The
               depth of representations is of central importance for many
               visual recognition tasks. Solely due to our extremely deep
               representations, we obtain a 28\% relative improvement on the
               COCO object detection dataset. Deep residual nets are
               foundations of our submissions to ILSVRC \& COCO 2015
               competitions1, where we also won the 1st places on the tasks of
               ImageNet detection, ImageNet localization, COCO detection, and
               COCO segmentation.",
  publisher = "IEEE",
  pages     = "770--778",
  month     =  jun,
  year      =  2016
}

@INCOLLECTION{LeCun1998-be,
  title     = "Convolutional networks for images, speech, and time series",
  booktitle = "The handbook of brain theory and neural networks",
  author    = "LeCun, Yann and Bengio, Yoshua",
  publisher = "MIT Press",
  pages     = "255--258",
  month     =  oct,
  year      =  1998,
  address   = "Cambridge, MA, USA"
}

@InProceedings{KingBa15,
  author    = {Kingma, Diederik and Ba, Jimmy},
  booktitle = {International Conference on Learning Representations (ICLR)},
  title     = {Adam: A Method for Stochastic Optimization},
  year      = {2015},
  address   = {San Diega, CA, USA},
  optmonth  = {12},
}

@INCOLLECTION{Rajnarayan2017-ml,
  title     = "{Bias-Variance} Trade-offs: Novel Applications",
  booktitle = "Encyclopedia of Machine Learning",
  author    = "Rajnarayan, Dev and Wolpert, David",
  editor    = "Sammut, Claude and Webb, Geoffrey I",
  publisher = "Springer US",
  pages     = "101--110",
  year      =  2010,
  address   = "Boston, MA"
}

@inproceedings{islam2021shape,
title={Shape or Texture: Understanding Discriminative Features in CNNs},
author={Md Amirul Islam and Matthew Kowal and Patrick Esser and Sen Jia and Bj{\"o}rn Ommer and Konstantinos G. Derpanis and Neil Bruce},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=NcFEZOi-rLa}
}

@article{Stephenson2021and,
  author       = {Cory Stephenson and
                  Tyler Lee},
  title        = {When and how epochwise double descent happens},
  journal      = {CoRR},
  volume       = {abs/2108.12006},
  year         = {2021},
  eprinttype    = {arXiv},
  eprint       = {2108.12006},
  timestamp    = {Thu, 02 Sep 2021 14:42:29 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-12006.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{Stephenson,
  author       = {Cory Stephenson and
                  Tyler Lee},
  title        = {When and how epochwise double descent happens},
  journal      = {CoRR},
  volume       = {abs/2108.12006},
  year         = {2021},
  eprinttype    = {arXiv},
  eprint       = {2108.12006},
  timestamp    = {Thu, 02 Sep 2021 14:42:29 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-12006.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{icpr2024iwase,
    author = {Iwase, Shun and Takahashi, Shuya and Inoue, Nakamasa and Yokota, Rio and Nakamura, Ryo and Kataoka, Hirokatsu and Maeda, Eisaku},
    title = {On the Relationship Between Double Descent of CNNs and Shape/Texture Bias Under Learning Process},
    booktitle = {"in press" International Conference on Pattern Recognition},
    year = {2024}
}

@inproceedings{Geirhos,
  author       = {Robert Geirhos and
                  Patricia Rubisch and
                  Claudio Michaelis and
                  Matthias Bethge and
                  Felix A. Wichmann and
                  Wieland Brendel},
  title = {ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  booktitle    = ICLR,
  year         = {2019},
}
@inproceedings{Ge,
author       = {Yunhao Ge and
                  Yao Xiao and
                  Zhi Xu and
                  Xingrui Wang and
                  Laurent Itti},
editor       = {Shai Avidan and
                  Gabriel J. Brostow and
                  Moustapha Ciss{\'{e}} and
                  Giovanni Maria Farinella and
                  Tal Hassner},
title        = {Contributions of Shape, Texture, and Color in Visual Recognition},
booktitle    = ECCV,
pages        = {369--386},
year         = {2022},
}