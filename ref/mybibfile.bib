@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{orekondy2019knockoff,
  title={Knockoff nets: Stealing functionality of black-box models},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition(CVPR)},
  pages={4954--4963},
  year={2019}
}

@article{orekondy2019prediction,
  title={Prediction poisoning: Towards defenses against dnn model stealing attacks},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  journal={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@ARTICLE{DD_STB,
  title     = "画像識別における形状・テクスチャ偏重度と二重降下現象の関係について",
  author    = "\UTF{9AD9}橋秀弥 and 井上中順 and 横田理央 and 片岡裕雄 and 前田英作",
  journal   = "IEICE Conferences Archives",
  publisher = "The Institute of Electronics, Information and Communication Engineers",
  volume    = "IEICE-122",
  number    = "IEICE-PRMU-404,IEICE-IBISML-405",
  pages     = "IEICE--PRMU--13,IEICE--IBISML--13--IEICE--PRMU--16,IEICE--IBISML--16",
  month     =  feb,
  year      =  2023
}

@ARTICLE{Belkin2018-yx,
  title     = "Reconciling modern machine learning practice and the bias-variance trade-off",
  author    = "Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik",
  month     =  dec,
  year      =  2018,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML",
  eprint        = "1812.11118"
}

@ARTICLE{Nakkiran2021,
  title     = "Deep double descent: where bigger models and more data hurt*",
  author    = "Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya",
  journal   = "J. Stat. Mech.",
  publisher = "IOP Publishing",
  volume    =  2021,
  number    =  12,
  pages     = "124003",
  month     =  dec,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Esser2020-bk,
  title     = "A Disentangling Invertible Interpretation Network for Explaining Latent Representations",
  author    = "Esser, Patrick and Rombach, Robin and Ommer, Bj{\"o}rn",
  month     =  apr,
  year      =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "2004.13166"
}

@INPROCEEDINGS{He2016-et,
  title     = "Deep Residual Learning for Image Recognition",
  booktitle = "2016 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})",
  author    = "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
  publisher = "IEEE",
  pages     = "770--778",
  month     =  jun,
  year      =  2016
}

@INCOLLECTION{LeCun1998-be,
  title     = "Convolutional networks for images, speech, and time series",
  booktitle = "The handbook of brain theory and neural networks",
  author    = "LeCun, Yann and Bengio, Yoshua",
  publisher = "MIT Press",
  pages     = "255--258",
  month     =  oct,
  year      =  1998,
  address   = "Cambridge, MA, USA"
}

@InProceedings{KingBa15,
  author    = {Kingma, Diederik and Ba, Jimmy},
  booktitle = {International Conference on Learning Representations (ICLR)},
  title     = {Adam: A Method for Stochastic Optimization},
  year      = {2015},
  address   = {San Diega, CA, USA},
  optmonth  = {12}
}

@INCOLLECTION{Rajnarayan2017-ml,
  title     = "{Bias-Variance} Trade-offs: Novel Applications",
  booktitle = "Encyclopedia of Machine Learning",
  author    = "Rajnarayan, Dev and Wolpert, David",
  editor    = "Sammut, Claude and Webb, Geoffrey I",
  publisher = "Springer US",
  pages     = "101--110",
  year      =  2010,
  address   = "Boston, MA"
}

@inproceedings{islam2021shape,
  title={Shape or Texture: Understanding Discriminative Features in CNNs},
  author={Md Amirul Islam and Matthew Kowal and Patrick Esser and Sen Jia and Bj{\"o}rn Ommer and Konstantinos G. Derpanis and Neil Bruce},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=NcFEZOi-rLa}
}

@article{Stephenson2021and,
  author    = {Cory Stephenson and Tyler Lee},
  title     = {When and how epochwise double descent happens},
  journal   = {CoRR},
  volume    = {abs/2108.12006},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2108.12006}
}

@inproceedings{icpr2024iwase,
  author    = {Iwase, Shun and Takahashi, Shuya and Inoue, Nakamasa and Yokota, Rio and Nakamura, Ryo and Kataoka, Hirokatsu and Maeda, Eisaku},
  title     = {On the Relationship Between Double Descent of CNNs and Shape/Texture Bias Under Learning Process},
  booktitle = {"in press" International Conference on Pattern Recognition},
  year      = {2024}
}

@inproceedings{Geirhos,
  author    = {Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
  title     = {ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  booktitle = {ICLR},
  year      = {2019}
}

@inproceedings{Ge,
  author    = {Yunhao Ge and Yao Xiao and Zhi Xu and Xingrui Wang and Laurent Itti},
  editor    = {Shai Avidan and Gabriel J. Brostow and Moustapha Ciss{\'{e}} and Giovanni Maria Farinella and Tal Hassner},
  title     = {Contributions of Shape, Texture, and Color in Visual Recognition},
  booktitle = {ECCV},
  pages     = {369--386},
  year      = {2022}
}

@article{cohen2017emnist,
  title     = {EMNIST: an extension of MNIST to handwritten letters}, 
  author    = {Gregory Cohen and Saeed Afshar and Jonathan Tapson and André van Schaik},
  year      = {2017},
  eprint    = {1702.05373},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV}
}

@inproceedings{AlexNet,
  author    = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2012},
  pages     = {1097--1105},
  url       = {https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks}
}

@inproceedings{VGGNet,
  author    = {Karen Simonyan and Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2015},
  url       = {https://arxiv.org/abs/1409.1556}
}

@article{ILSVRC15,
  author    = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  title     = {ImageNet Large Scale Visual Recognition Challenge},
  journal   = {International Journal of Computer Vision},
  year      = {2015},
  volume    = {115},
  number    = {3},
  pages     = {211--252},
  doi       = {10.1007/s11263-015-0816-y}
}

@inproceedings{DBLP:conf/icml/BahdanauCB14,
  author    = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {Proceedings of the 3rd International Conference on Learning Representations (ICLR)},
  year      = {2015},
  url       = {http://arxiv.org/abs/1409.0473}
}

@inproceedings{DBLP:conf/cvpr/ZeilerF14,
  author    = {Matthew D. Zeiler and Rob Fergus},
  title     = {Visualizing and Understanding Convolutional Networks},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year      = {2014},
  pages     = {818--833},
  doi       = {10.1007/978-3-319-10590-1_53}
}

@article{JMLR:v15:srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@inproceedings{LeNet,
  added-at = {2017-05-15T10:09:50.000+0200},
  author = {LeCun, Yann and Bottou, Léon and Bengio, Yoshua and Haffner, Patrick},
  biburl = {https://www.bibsonomy.org/bibtex/29aa18bc67d862bdb83b6081e5506f050/albinzehe},
  booktitle = {Proceedings of the IEEE},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665},
  file = {:neural_nets/lecun-98.pdf:PDF;:lecun-98.pdf:PDF},
  groups = {public},
  interhash = {7a82cccacd23cf06b25ff5325a6c86c7},
  intrahash = {9aa18bc67d862bdb83b6081e5506f050},
  keywords = {cnn neuralnets},
  number = 11,
  pages = {2278--2324},
  timestamp = {2017-05-15T10:09:50.000+0200},
  title = {Gradient-Based Learning Applied to Document Recognition},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665},
  username = {mhwombat},
  volume = 86,
  year = 1998
}

@inproceedings{ResNet,
  added-at = {2021-05-01T22:31:00.000+0200},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  biburl = {https://www.bibsonomy.org/bibtex/2f08d8f1a1881a5c9ee27060e40ada500/nosebrain},
  booktitle = {Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition},
  doi = {10.1109/CVPR.2016.90},
  interhash = {d2fe72bcc2c02bacc9fae990ec4d4927},
  intrahash = {f08d8f1a1881a5c9ee27060e40ada500},
  issn = {1063-6919},
  keywords = {image recognition resnet},
  location = {Las Vegas, NV, USA},
  month = jun,
  pages = {770--778},
  publisher = {IEEE},
  series = {CVPR '16},
  timestamp = {2021-05-01T22:31:00.000+0200},
  title = {{Deep Residual Learning for Image Recognition}},
  url = {http://ieeexplore.ieee.org/document/7780459},
  year = 2016
}

@article{Belkin_2019,
   title={Reconciling modern machine-learning practice and the classical bias–variance trade-off},
   volume={116},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.1903070116},
   DOI={10.1073/pnas.1903070116},
   number={32},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
   year={2019},
   month=jul, pages={15849–15854}
}

@INPROCEEDINGS{He2016,
  title     = "Deep Residual Learning for Image Recognition",
  booktitle = "2016 {IEEE} Conference on Computer Vision and Pattern
               Recognition ({CVPR})",
  author    = "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
  abstract  = "Deeper neural networks are more difficult to train. We present a
               residual learning framework to ease the training of networks
               that are substantially deeper than those used previously. We
               explicitly reformulate the layers as learning residual functions
               with reference to the layer inputs, instead of learning
               unreferenced functions. We provide comprehensive empirical
               evidence showing that these residual networks are easier to
               optimize, and can gain accuracy from considerably increased
               depth. On the ImageNet dataset we evaluate residual nets with a
               depth of up to 152 layers - 8$\times$ deeper than VGG nets [40]
               but still having lower complexity. An ensemble of these residual
               nets achieves 3.57\% error on the ImageNet test set. This result
               won the 1st place on the ILSVRC 2015 classification task. We
               also present analysis on CIFAR-10 with 100 and 1000 layers. The
               depth of representations is of central importance for many
               visual recognition tasks. Solely due to our extremely deep
               representations, we obtain a 28\% relative improvement on the
               COCO object detection dataset. Deep residual nets are
               foundations of our submissions to ILSVRC \& COCO 2015
               competitions1, where we also won the 1st places on the tasks of
               ImageNet detection, ImageNet localization, COCO detection, and
               COCO segmentation.",
  publisher = "IEEE",
  pages     = "770--778",
  month     =  jun,
  year      =  2016
}

@misc{ViT,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@inproceedings{Pezeshki22,
  title = 	 {Multi-scale Feature Learning Dynamics: Insights for Double Descent},
  author =       {Pezeshki, Mohammad and Mitra, Amartya and Bengio, Yoshua and Lajoie, Guillaume},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {17669--17690},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/pezeshki22a/pezeshki22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/pezeshki22a.html},
  abstract = 	 {An intriguing phenomenon that arises from the high-dimensional learning dynamics of neural networks is the phenomenon of “double descent”. The more commonly studied aspect of this phenomenon corresponds to <em>model-wise</em> double descent where the test error exhibits a second descent with increasing model complexity, beyond the classical U-shaped error curve. In this work, we investigate the origins of the less studied <em>epoch-wise</em> double descent in which the test error undergoes two non-monotonous transitions, or descents as the training time increases. We study a linear teacher-student setup exhibiting epoch-wise double descent similar to that in deep neural networks. In this setting, we derive closed-form analytical expressions describing the generalization error in terms of low-dimensional scalar macroscopic variables. We find that double descent can be attributed to distinct features being learned at different scales: as fast-learning features overfit, slower-learning features start to fit, resulting in a second descent in test error. We validate our findings through numerical simulations where our theory accurately predicts empirical findings and remains consistent with observations in deep neural networks.}
}

@inproceedings{Arpit2017,
  author = {Arpit, Devansh and Jastrzundefinedbski, Stanis\l{}aw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S. and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and Lacoste-Julien, Simon},
  title = {A closer look at memorization in deep networks},
  year = {2017},
  publisher = {JMLR.org},
  abstract = {We examine the role of memorization in deep learning, drawing connections to capacity, generalization, and adversarial robustness. While deep networks are capable of memorizing noise data, our results suggest that they tend to prioritize learning simple patterns first. In our experiments, we expose qualitative differences in gradient-based optimization of deep neural networks (DNNs) on noise vs. real data. We also demonstrate that for appropriately tuned explicit regularization (e.g., dropout) we can degrade DNN training performance on noise datasets without compromising generalization on real data. Our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization.},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
  pages = {233–242},
  numpages = {10},
  location = {Sydney, NSW, Australia},
  series = {ICML'17}
}

@inproceedings{Jeffares2024,
  title={Looking at Deep Learning Phenomena Through a Telescoping Lens},
  author={Alan Jeffares and Alicia Curth and Mihaela van der Schaar},
  booktitle={High-dimensional Learning Dynamics 2024: The Emergence of Structure and Reasoning},
  year={2024},
  url={https://openreview.net/forum?id=hJ7hfAzsuT}
}
